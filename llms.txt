AI Agents Infrastructure and LLMops Landscape - AI-optimized documentation for GitMCP

Summary
This project is a living, opinionated landscape of agentic infrastructure and LLMOps: orchestration frameworks, memory/vector databases, observability/evals, gateways, protocols, and compute. Use it to research options, compare trade‑offs, and plan architectures for agent workflows.

How to Use with GitMCP
- MCP URL for this repo: https://gitmcp.io/dudany/ai-infra-landscape.github.io
- Typical flow:
  1) Connect your MCP client to this repo.
  2) Ask discovery/comparison questions to explore options for your agentic use case.
  3) Get suggested next MCP servers (e.g., LangChain, LangGraph, vector DBs) to start building.

Purpose of this file
- This llms.txt is the AI‑optimized entrypoint for GitMCP and other agents. It summarizes the project and points to the canonical dataset used by the site.
- For detailed, per‑tool data (including GitMCP endpoints), fetch `data/tools_descriptions.json`.

Useful Prompts
- "Summarize the layers and components covered here and what problems each solves."
- "Given a workflow that needs stateful multi‑agent orchestration with human‑in‑the‑loop, which frameworks should I consider and why?"
- "Compare Weaviate vs Qdrant vs Supabase pgvector for my RAG use case (cost, ops, ecosystem)."
- "Recommend observability/evaluation tools for a LangGraph‑based agent in production."
- "List relevant MCP servers to connect after research to begin implementation."
- "Propose an OSS‑only starter stack for a TypeScript agent (runtime, memory, observability, gateway)."
- "Compare LangGraph vs CrewAI vs Mastra Agents for long‑running, checkpointed workflows with retries."
- "I need RAG with strict PII access and audit logs-suggest DB + identity + gateway options."
- "Select an MCP‑aware gateway with auth, rate limits, and tracing (Envoy AI Gateway vs Kong vs LiteLLM vs Portkey)."
- "Pick a vector DB for 100k docs with hybrid search and low ops overhead."
- "Recommend eval/observability for a Python stack: Langfuse vs Arize Phoenix vs Datadog LLM Observability."
- "Design a low‑latency inference path: vLLM vs TGI vs Triton; when to add KServe or Ray Serve."
- "Optimize context costs: when to use LLMLingua compression vs restructuring retrieval."
- "Constrained tool I/O: how to enforce JSON schemas (Outlines or model‑side constraints)."
- "Memory for multi‑agent teams: Mem0 vs native framework memory; trade‑offs and patterns."
- "Prefer serverless or scale‑to‑zero: pick components accordingly (e.g., Pinecone Serverless, Neon)."
- "On‑prem constraints: propose a fully OSS stack that runs on Kubernetes."
- "Identity and access for agents: Auth0/Okta vs OSS (Zitadel, Ory) and how to integrate with tools."
- "Enterprise MCP identity/context management-when to use Webrix vs DIY with gateway policies."
- "Compare Weaviate vs Qdrant vs Pinecone for multi‑tenant isolation and cost controls."
- "High‑throughput generation with KV cache: vLLM tuning basics and when to shard."
- "GPU cluster setup for finetuning: NVIDIA GPU Operator + Ray/TorchTune/Unsloth choices."
- "Fine‑tuning path for Llama 3.x: Axolotl vs TorchTune vs Unsloth; when to avoid finetuning."
- "Observability standards: how to adopt OpenTelemetry GenAI across runtime, gateway, and evals."
- "Suggest a reference stack for agent + RAG + evals + gateway for a small team shipping in 2 weeks."
- "After picking a stack, list the exact MCP servers to connect to start building."

What GitMCP Will Find Here
- Prioritized doc: this llms.txt; fallback to README and site content
- Important Files map:
  - data/tools_descriptions.json - primary tools dataset powering the UI; includes gitmcp_url for repos
  - Note: MCP endpoints should be discovered from each tool's `gitmcp_url` in this dataset

Data Schema (data/tools_descriptions.json)
- tools[]: array of tool objects with commonly used fields:
  - name: string
  - type: string (e.g., "open source sdk", "proprietary", "protocol")
  - layer: string[] (e.g., "Agent Runtime")
  - component: string[] (e.g., "Agent Orchestration & Frameworks")
  - summary: string (brief description)
  - docs_url: string | null
  - github_url: string | null
  - gitmcp_url: string (auto-derived when github_url points to a GitHub repo)
  - icon_url: string (optional)
  - oss: boolean | string (some entries use true/false or "mixed")
  - vendor, notes, last_known_update, license, maturity, enterprise_ready, recent_updates (optional metadata)
- The UI groups by layer, then component, and renders tool cards with icon, name, and normalized type label.

MCP‑Oriented Q&A
- Discover options: Ask about layers/components relevant to your use case (e.g., evals, memory, gateways, orchestration).
- Compare tools: Ask for trade‑offs (operational complexity, ecosystem fit, licensing, maturity).
- Architecture planning: Ask for a reference stack for your workload (e.g., LangGraph + vector DB + observability + gateway).
- Next steps: Request a short list of MCP servers to connect for implementation (e.g., LangChain, LangGraph, LlamaIndex, Weaviate/Qdrant, Langfuse, Supabase).

Recommended Follow‑up MCP Servers
- LangChain: https://gitmcp.io/langchain-ai/langchain
- LangGraph: https://gitmcp.io/langchain-ai/langgraph
- LlamaIndex: https://gitmcp.io/run-llama/llama_index
- Weaviate: https://gitmcp.io/weaviate/weaviate
- Qdrant: https://gitmcp.io/qdrant/qdrant
- Supabase: https://gitmcp.io/supabase/supabase
- Langfuse: https://gitmcp.io/langfuse/langfuse

Client Config Snippet (example)
{
  "mcpServers": {
    "ai-infra-landscape.github.io Docs": {
      "url": "https://gitmcp.io/dudany/ai-infra-landscape.github.io"
    }
  }
}

Notes
- This site is client‑side only; no server required. Content is static but updated regularly via the dataset.
- Prefer the layers/components to zoom into the domain you care about, then dive into individual tools and linked docs.
